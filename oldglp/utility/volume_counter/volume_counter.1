.TH VOLUME_COUNTER 1
.SH NAME
volume_counter - counts earthquakes in a GCLgrid3d object
.SH SYNOPSIS
.nf
volume_counter db out [-pf pffile -v] < infile
.SH DESCRIPTION
.LP
Large earthquake catalogs present a problem to visualization with
conventional earthquake epicenter plots let alone their 3D equivalent
because the number of points can be overwhelming and obscure details
that might be of interest.   This program takes an event->origin 
database and builds a GCLvectorfield3d volume.   The output field
is stored as a 2 vector for efficiency in the calculation.  Component 0
contains an estimate of the number of earthquakes per unit volume
at any point in a spherical shaped region surrounding that grid point.
Component 1 contains a quantity I call the fault area/volume ratio.   
(see below for the formula)
.LP
The algorithm used is fairly simple.   The program builds a GCLgrid3d
object driven by a pf control file (see below).  The base grid is 
a uniform grid mapped to earth coordinates as described in the original
GCLgrid paper by Fan et al.   At each point in this volume the program 
counts how many earthquakes in the parent db are within a specified 
radius of that point.   The count is normalized by the volume of 
the spherical region and saved at each grid point.   
In addition, it also makes an estimate of the slip area for each
event from the following relationship that can be derived between
moment magnitude and fault area:   log A = M_o - 3.296.    The program
blindly substitutes whatever magnitude is requested for M_o.   Note
this metric has the effect of essentially normalized with a b value of 1.0. 
Thus, for example, in the area calculation 10 magnitude 3s count the same
as one magnitude 4.  
.LP
Note this program eats up the entire catalog and stores it in memory 
to make the processing reasonably fast.  It is thus a fairly large 
memory algorithm if used on a large catalog over a large area with
many nodes.  Be further warned that because it has to test
every event for every node in a 3D grid, the run times can be very long 
if the grid is large and the catalog is large.   e.g. a modest grid
for the Alaska catalog took about 16 hours to run on a 2012 vintage
Mac computer.   
.LP
The first argument is required and is the database name.   The second
is the name to be assigned to the output field that will be stored 
in the db in the gclfield table.  
.SH OPTIONS
.IP -pf
Change the parameter file name.  (WARNING:  this program currently uses
a modified pf file reader that will NOT automatically append the ".pf" 
tag so this must be the full file name.)
.IP -ss
Apply next argument as a subset condition (antelope db expression) to
the event->origin join before processing. 
.IP -v
Run in verbose mode.  This is highly recommended for large catalogs
as in verbose mode a message is posted after each run through the 
fastest (z) index in the grid.
.SH PARAMETER FILE
.LP
The following are exactly as in makegclgrid(3):  delta_x1,
delta_x2, delta_x3, gridfile_directory, gridname, n1, n2, n3,
origin_latitude, origin_longitude, origin_offset_x1, origin_offset_x2,
and x_axis_azimuth.
.LP
The following relate to handling magnitudes.   The boolean 
\fIuse_netmag\fR controls handling of the netmag table.  When true
only rows of event->origin that join with netmag will be used.  
Only one magnitude will be used for area conversion.   The attribute
the program will actually try to extract is the defined by 
\fImagnitude_attribute\fR.   This parameter should use a full 
table.attribute name to avoid potentially mysterious aborts.   
The \fInull_magnitude_default\fR sets undefined magnitudes to this
value.   Normal practice should be to set this to something near the
detection floor of the network.

.SH DIAGNOSTICS
.LP
Information diagnostics that are hopefully normally clear are
sent to stdout through the C++ throw-catch mechanism.
.SH "BUGS AND CAVEATS"
.LP
This program can run a very long time on large catalogs.  If you 
do not need the full area of a catalog use a subset condition 
to reduce the size of the relavant events as this can 
dramatically reduce run times.
.SH AUTHOR
Prof. Gary L. Pavlis (pavlis@indiana.edu)
